{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:11.021505Z",
     "iopub.status.busy": "2021-03-06T00:22:11.020846Z",
     "iopub.status.idle": "2021-03-06T00:22:12.044131Z",
     "shell.execute_reply": "2021-03-06T00:22:12.044658Z"
    },
    "papermill": {
     "duration": 1.085397,
     "end_time": "2021-03-06T00:22:12.045008",
     "exception": false,
     "start_time": "2021-03-06T00:22:10.959611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tj/wmx_dq2d6ml43vdxr8h6yllh0000gn/T/ipykernel_7161/241286848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[0;31m# linear algebra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m \u001b[0;31m# Visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m \u001b[0;31m# Visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python37/lib/python3.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0m__mkl_version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{MajorVersion}.{MinorVersion}.{UpdateVersion}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import seaborn as sns # Visualization\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "from colorama import Fore\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "import warnings # Supress warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:12.158796Z",
     "iopub.status.busy": "2021-03-06T00:22:12.158118Z",
     "iopub.status.idle": "2021-03-06T00:22:12.162765Z",
     "shell.execute_reply": "2021-03-06T00:22:12.163189Z"
    },
    "papermill": {
     "duration": 0.063227,
     "end_time": "2021-03-06T00:22:12.163395",
     "exception": false,
     "start_time": "2021-03-06T00:22:12.100168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))\n",
    "        pass\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:12.608013Z",
     "iopub.status.busy": "2021-03-06T00:22:12.607352Z",
     "iopub.status.idle": "2021-03-06T00:22:12.664659Z",
     "shell.execute_reply": "2021-03-06T00:22:12.665090Z"
    },
    "papermill": {
     "duration": 0.115605,
     "end_time": "2021-03-06T00:22:12.665259",
     "exception": false,
     "start_time": "2021-03-06T00:22:12.549654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'./No_All_Score.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:13.162543Z",
     "iopub.status.busy": "2021-03-06T00:22:13.161851Z",
     "iopub.status.idle": "2021-03-06T00:22:13.320386Z",
     "shell.execute_reply": "2021-03-06T00:22:13.320806Z"
    },
    "papermill": {
     "duration": 0.234964,
     "end_time": "2021-03-06T00:22:13.320977",
     "exception": false,
     "start_time": "2021-03-06T00:22:13.086013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date \n",
    "from datetime import datetime, date\n",
    "\n",
    "df['year'] = df['year'].astype(str)  # convert integer to string\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y%m%d')  # convert to datetime object\n",
    "df.head(20).style.set_properties(subset=['year'], **{'background-color': 'dodgerblue'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:40.430396Z",
     "iopub.status.busy": "2021-03-06T00:22:40.429429Z",
     "iopub.status.idle": "2021-03-06T00:22:40.433388Z",
     "shell.execute_reply": "2021-03-06T00:22:40.432727Z"
    },
    "papermill": {
     "duration": 0.128652,
     "end_time": "2021-03-06T00:22:40.433526",
     "exception": false,
     "start_time": "2021-03-06T00:22:40.304874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = int(0.80 * len(df))\n",
    "test_size = len(df) - train_size\n",
    "\n",
    "univariate_df = df[['year', 'score']].copy()\n",
    "univariate_df.columns = ['ds', 'y']\n",
    "\n",
    "train = univariate_df.iloc[:train_size, :]\n",
    "\n",
    "x_train, y_train = pd.DataFrame(univariate_df.iloc[:train_size, 0]), pd.DataFrame(univariate_df.iloc[:train_size, 1])\n",
    "x_valid, y_valid = pd.DataFrame(univariate_df.iloc[train_size:, 0]), pd.DataFrame(univariate_df.iloc[train_size:, 1])\n",
    "\n",
    "print(len(x_train), len(x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.11339,
     "end_time": "2021-03-06T00:22:40.661719",
     "exception": false,
     "start_time": "2021-03-06T00:22:40.548329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='1'></a>\n",
    "## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:center\">1 Prophet</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:40.896590Z",
     "iopub.status.busy": "2021-03-06T00:22:40.895784Z",
     "iopub.status.idle": "2021-03-06T00:22:44.387192Z",
     "shell.execute_reply": "2021-03-06T00:22:44.387688Z"
    },
    "papermill": {
     "duration": 3.61251,
     "end_time": "2021-03-06T00:22:44.387853",
     "exception": false,
     "start_time": "2021-03-06T00:22:40.775343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "from fbprophet import Prophet\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model = Prophet()\n",
    "model.fit(train)\n",
    "\n",
    "# x_valid = model.make_future_dataframe(periods=test_size, freq='w')\n",
    "\n",
    "# Predict on valid set\n",
    "y_pred = model.predict(x_valid)\n",
    "\n",
    "# Calcuate metrics\n",
    "score_mae = mean_absolute_error(y_valid, y_pred.tail(test_size)['yhat'])\n",
    "score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred.tail(test_size)['yhat']))\n",
    "\n",
    "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:44.617516Z",
     "iopub.status.busy": "2021-03-06T00:22:44.616932Z",
     "iopub.status.idle": "2021-03-06T00:22:44.905826Z",
     "shell.execute_reply": "2021-03-06T00:22:44.906310Z"
    },
    "papermill": {
     "duration": 0.405671,
     "end_time": "2021-03-06T00:22:44.906492",
     "exception": false,
     "start_time": "2021-03-06T00:22:44.500821",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the forecast\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "model.plot(y_pred, ax=ax)\n",
    "sns.lineplot(x=x_valid['ds'], y=y_valid['y'], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
    "\n",
    "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
    "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
    "ax.set_ylabel(ylabel='Depth to Groundwater', fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.114416,
     "end_time": "2021-03-06T00:22:45.137674",
     "exception": false,
     "start_time": "2021-03-06T00:22:45.023258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='2'></a>\n",
    "## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:center\">2 ARIMA</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:45.377930Z",
     "iopub.status.busy": "2021-03-06T00:22:45.377315Z",
     "iopub.status.idle": "2021-03-06T00:22:45.479070Z",
     "shell.execute_reply": "2021-03-06T00:22:45.478451Z"
    },
    "papermill": {
     "duration": 0.225397,
     "end_time": "2021-03-06T00:22:45.479207",
     "exception": false,
     "start_time": "2021-03-06T00:22:45.253810",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.tsa.arima.ARIMA(y_train, order=(1,1,1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "print(y_valid)\n",
    "y_pred = model_fit.forecast(steps=len(y_valid))\n",
    "\n",
    "\n",
    "# y_pred, stderr, conf_int = model_fit.forecast(steps=len(y_valid), alpha=0.05)\n",
    "\n",
    "# y_pred, stderr = model_fit.forecast(len(y_valid))\n",
    "\n",
    "score_mae = mean_absolute_error(y_valid, y_pred)\n",
    "score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "#from statsmodels.tsa.arima_model import ARIMA #yjp it is not work\n",
    "\n",
    "# Fit model\n",
    "#model = ARIMA(y_train, order=(1,1,1))#yjp it is not work\n",
    "model = sm.tsa.arima.ARIMA(y_train, order=(1,1,1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Prediction with ARIMA\n",
    "#y_pred, se, conf = model_fit.forecast(90)#yjp it is not work\n",
    "y_pred = model_fit.forecast(86)\n",
    "\n",
    "# Calcuate metrics\n",
    "score_mae = mean_absolute_error(y_valid, y_pred)\n",
    "score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-03-06T00:22:45.736538Z",
     "iopub.status.busy": "2021-03-06T00:22:45.735556Z",
     "iopub.status.idle": "2021-03-06T00:22:45.962612Z",
     "shell.execute_reply": "2021-03-06T00:22:45.963119Z"
    },
    "papermill": {
     "duration": 0.368285,
     "end_time": "2021-03-06T00:22:45.963308",
     "exception": false,
     "start_time": "2021-03-06T00:22:45.595023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "\n",
    "#model_fit.plot_predict(1, 599, ax=ax)#yjp it is not work\n",
    "model_fit.predict(1, 599, ax=ax)\n",
    "sns.lineplot(x=x_valid.index, y=y_valid['y'], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
    "\n",
    "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
    "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
    "ax.set_ylabel(ylabel='Depth to Groundwater', fontsize=14)\n",
    "\n",
    "ax.set_ylim(-35, -18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "# Plot predictions\n",
    "model_fit.plot_predict(start='2019-06-01', end='2020-03-31', ax=ax)\n",
    "\n",
    "# Plot ground truth\n",
    "sns.lineplot(x=x_valid.index, y=y_valid['y'], ax=ax, color='orange', label='Ground truth')\n",
    "\n",
    "# Set plot properties\n",
    "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
    "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
    "ax.set_ylabel(ylabel='Depth to Groundwater', fontsize=14)\n",
    "ax.set_ylim(-35, -18)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.133804,
     "end_time": "2021-03-06T00:23:20.056898",
     "exception": false,
     "start_time": "2021-03-06T00:23:19.923094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='5.1.4'></a>\n",
    "## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:100%; text-align:center\">3 LSTM</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-03-06T00:23:20.328223Z",
     "iopub.status.busy": "2021-03-06T00:23:20.327618Z",
     "iopub.status.idle": "2021-03-06T00:23:20.335252Z",
     "shell.execute_reply": "2021-03-06T00:23:20.335705Z"
    },
    "papermill": {
     "duration": 0.146671,
     "end_time": "2021-03-06T00:23:20.335876",
     "exception": false,
     "start_time": "2021-03-06T00:23:20.189205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = univariate_df.filter(['y'])\n",
    "#Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 0))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-03-06T00:23:20.610484Z",
     "iopub.status.busy": "2021-03-06T00:23:20.609873Z",
     "iopub.status.idle": "2021-03-06T00:23:20.619658Z",
     "shell.execute_reply": "2021-03-06T00:23:20.619162Z"
    },
    "papermill": {
     "duration": 0.147719,
     "end_time": "2021-03-06T00:23:20.619801",
     "exception": false,
     "start_time": "2021-03-06T00:23:20.472082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines the rolling window\n",
    "look_back = 52\n",
    "# Split into train and test sets\n",
    "train, test = scaled_data[:train_size-look_back,:], scaled_data[train_size-look_back:,:]\n",
    "print(train)\n",
    "print(test)\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(look_back, len(dataset)):\n",
    "        a = dataset[i-look_back:i, 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-03-06T00:23:20.940909Z",
     "iopub.status.busy": "2021-03-06T00:23:20.939852Z",
     "iopub.status.idle": "2021-03-06T00:23:35.262184Z",
     "shell.execute_reply": "2021-03-06T00:23:35.261260Z"
    },
    "papermill": {
     "duration": 14.47603,
     "end_time": "2021-03-06T00:23:35.262382",
     "exception": false,
     "start_time": "2021-03-06T00:23:20.786352",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "#Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "# model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=100, validation_data=(x_test, y_test))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T00:23:35.588250Z",
     "iopub.status.busy": "2021-03-06T00:23:35.586847Z",
     "iopub.status.idle": "2021-03-06T00:23:36.339882Z",
     "shell.execute_reply": "2021-03-06T00:23:36.338773Z"
    },
    "papermill": {
     "duration": 0.916754,
     "end_time": "2021-03-06T00:23:36.340101",
     "exception": false,
     "start_time": "2021-03-06T00:23:35.423347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets predict with the model\n",
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)\n",
    "\n",
    "# invert predictions\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "# Get the root mean squared error (RMSE) and MAE\n",
    "score_rmse = np.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\n",
    "score_mae = mean_absolute_error(y_test[0], test_predict[:,0])\n",
    "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-03-06T00:23:36.692801Z",
     "iopub.status.busy": "2021-03-06T00:23:36.691871Z",
     "iopub.status.idle": "2021-03-06T00:23:36.965775Z",
     "shell.execute_reply": "2021-03-06T00:23:36.965179Z"
    },
    "papermill": {
     "duration": 0.466771,
     "end_time": "2021-03-06T00:23:36.965947",
     "exception": false,
     "start_time": "2021-03-06T00:23:36.499176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_ticks = univariate_df.head(train_size)['ds']\n",
    "y_train = univariate_df.head(train_size)['y']\n",
    "x_test_ticks = univariate_df.tail(test_size)['ds']\n",
    "\n",
    "# Plot the forecast\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "# Plot train set\n",
    "sns.lineplot(x=x_train_ticks, y=y_train, ax=ax, label='Train Set')\n",
    "\n",
    "# Plot prediction\n",
    "sns.lineplot(x=x_test_ticks, y=test_predict[:, 0], ax=ax, color='green', label='Prediction')\n",
    "\n",
    "# Calculate standard deviation of predictions\n",
    "prediction_std = np.std(test_predict[:, 0])\n",
    "\n",
    "# Calculate upper and lower bounds of confidence interval\n",
    "std_multiplier = 2  # 调整置信区间的倍数\n",
    "lower_bound = test_predict[:, 0] - std_multiplier * prediction_std\n",
    "upper_bound = test_predict[:, 0] + std_multiplier * prediction_std\n",
    "\n",
    "# Plot confidence interval as shaded area\n",
    "ax.fill_between(x_test_ticks, lower_bound, upper_bound, color='DodgerBlue', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "# Plot ground truth\n",
    "sns.lineplot(x=x_test_ticks, y=y_test[0], ax=ax, color='orange', label='Ground truth')\n",
    "\n",
    "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
    "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
    "ax.set_ylabel(ylabel='Score', fontsize=14)\n",
    "\n",
    "plt.savefig('./Y_FFFF_Prediction100.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-Lstm模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = univariate_df.filter(['y'])\n",
    "#Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 0))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the rolling window\n",
    "look_back = 52\n",
    "# Split into train and test sets\n",
    "train, test = scaled_data[:train_size-look_back,:], scaled_data[train_size-look_back:,:]\n",
    "print(train)\n",
    "print(test)\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(look_back, len(dataset)):\n",
    "        a = dataset[i-look_back:i, 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print(len(x_train), len(x_test),len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM\n",
    "\n",
    "# Build the Bi-LSTM model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=100, validation_data=(x_test, y_test))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets predict with the model\n",
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)\n",
    "\n",
    "# invert predictions\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "# Get the root mean squared error (RMSE) and MAE\n",
    "score_rmse = np.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\n",
    "score_mae = mean_absolute_error(y_test[0], test_predict[:,0])\n",
    "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ticks = univariate_df.head(train_size)['ds']\n",
    "y_train = univariate_df.head(train_size)['y']\n",
    "x_test_ticks = univariate_df.tail(test_size)['ds']\n",
    "\n",
    "# Plot the forecast\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "# Plot train set\n",
    "sns.lineplot(x=x_train_ticks, y=y_train, ax=ax, label='Train Set')\n",
    "\n",
    "# Plot prediction\n",
    "sns.lineplot(x=x_test_ticks, y=test_predict[:, 0], ax=ax, color='green', label='Prediction')\n",
    "\n",
    "# Calculate standard deviation of predictions\n",
    "prediction_std = np.std(test_predict[:, 0])\n",
    "\n",
    "# Calculate upper and lower bounds of confidence interval\n",
    "std_multiplier = 2  # 调整置信区间的倍数\n",
    "lower_bound = test_predict[:, 0] - std_multiplier * prediction_std\n",
    "upper_bound = test_predict[:, 0] + std_multiplier * prediction_std\n",
    "\n",
    "# Plot confidence interval as shaded area\n",
    "ax.fill_between(x_test_ticks, lower_bound, upper_bound, color='DodgerBlue', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "# Plot ground truth\n",
    "sns.lineplot(x=x_test_ticks, y=y_test[0], ax=ax, color='orange', label='Ground truth')\n",
    "\n",
    "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
    "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
    "ax.set_ylabel(ylabel='Score', fontsize=14)\n",
    "\n",
    "plt.savefig('./Y_Bi_F_Prediction100.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = univariate_df.filter(['y'])\n",
    "#Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 0))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the rolling window\n",
    "look_back = 52\n",
    "# Split into train and test sets\n",
    "train, test = scaled_data[:train_size-look_back,:], scaled_data[train_size-look_back:,:]\n",
    "print(train)\n",
    "print(test)\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(look_back, len(dataset)):\n",
    "        a = dataset[i-look_back:i, 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "\n",
    "#Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(128, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "model.add(SimpleRNN(64, return_sequences=False))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=100, validation_data=(x_test, y_test))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets predict with the model\n",
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)\n",
    "\n",
    "# invert predictions\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "# Get the root mean squared error (RMSE) and MAE\n",
    "score_rmse = np.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\n",
    "score_mae = mean_absolute_error(y_test[0], test_predict[:,0])\n",
    "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ticks = univariate_df.head(train_size)['ds']\n",
    "y_train = univariate_df.head(train_size)['y']\n",
    "x_test_ticks = univariate_df.tail(test_size)['ds']\n",
    "\n",
    "# Plot the forecast\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "sns.lineplot(x=x_train_ticks, y=y_train, ax=ax, label='Train Set') #navajowhite\n",
    "sns.lineplot(x=x_test_ticks, y=test_predict[:,0], ax=ax, color='green', label='Prediction') #navajowhite\n",
    "sns.lineplot(x=x_test_ticks, y=y_test[0], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
    "\n",
    "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
    "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
    "ax.set_ylabel(ylabel='Score', fontsize=14)\n",
    "plt.savefig('./Y_Rnn_Prediction100.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = univariate_df.filter(['y'])\n",
    "#Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 0))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the rolling window\n",
    "look_back = 52\n",
    "# Split into train and test sets\n",
    "train, test = scaled_data[:train_size-look_back,:], scaled_data[train_size-look_back:,:]\n",
    "print(train)\n",
    "print(test)\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(look_back, len(dataset)):\n",
    "        a = dataset[i-look_back:i, 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU\n",
    "\n",
    "#Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(GRU(128, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "# model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape)))\n",
    "model.add(GRU(64, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=100, validation_data=(x_test, y_test))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets predict with the model\n",
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)\n",
    "\n",
    "# invert predictions\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "# Get the root mean squared error (RMSE) and MAE\n",
    "score_rmse = np.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\n",
    "score_mae = mean_absolute_error(y_test[0], test_predict[:,0])\n",
    "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ticks = univariate_df.head(train_size)['ds']\n",
    "y_train = univariate_df.head(train_size)['y']\n",
    "x_test_ticks = univariate_df.tail(test_size)['ds']\n",
    "\n",
    "# Plot the forecast\n",
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "sns.lineplot(x=x_train_ticks, y=y_train, ax=ax, label='Train Set') #navajowhite\n",
    "sns.lineplot(x=x_test_ticks, y=test_predict[:,0], ax=ax, color='green', label='Prediction') #navajowhite\n",
    "sns.lineplot(x=x_test_ticks, y=y_test[0], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
    "\n",
    "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
    "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
    "ax.set_ylabel(ylabel='Score', fontsize=14)\n",
    "plt.savefig('./Y_GRU_Prediction100_1.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 99.003821,
   "end_time": "2021-03-06T00:23:44.654890",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-06T00:22:05.651069",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
